{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3fdae13-de8f-4743-8091-1ccb5cfb2c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Come --> 21\n",
      "on --> 13\n",
      "John --> 11\n",
      "Doe --> 12\n",
      "what --> 0\n",
      "are --> 21\n",
      "you --> 0\n",
      "doing --> 21\n",
      "? --> 0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Charger le modèle de langue en anglais de spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# La liste des étiquettes de classification des chunks avec les indices correspondants\n",
    "chunk_tags_mapping = {\n",
    "    0: 'O', 1: 'B-ADJP', 2: 'I-ADJP', 3: 'B-ADVP', 4: 'I-ADVP',\n",
    "    5: 'B-CONJP', 6: 'I-CONJP', 7: 'B-INTJ', 8: 'I-INTJ',\n",
    "    9: 'B-LST', 10: 'I-LST', 11: 'B-NP', 12: 'I-NP',\n",
    "    13: 'B-PP', 14: 'I-PP', 15: 'B-PRT', 16: 'I-PRT',\n",
    "    17: 'B-SBAR', 18: 'I-SBAR', 19: 'B-UCP', 20: 'I-UCP',\n",
    "    21: 'B-VP', 22: 'I-VP'\n",
    "}\n",
    "\n",
    "# Phrase à analyser\n",
    "sentence = \"Metropolitan France was settled during the Iron Age by Celtic tribes known as Gauls before Rome annexed the area in 51 BC, leading to a distinct Gallo-Roman culture. In the Early Middle Ages, the Germanic Franks formed the Kingdom of Francia, which became the heartland of the Carolingian Empire. The Treaty of Verdun of 843 partitioned the empire, with West Francia evolving into the Kingdom of France. In the High Middle Ages, France was a powerful but decentralized feudal kingdom, but from the mid-14th to the mid-15th centuries, France was plunged into a dynastic conflict with England known as the Hundred Years' War. In the 16th century, the French Renaissance saw culture flourish and a French colonial empire rise.[14] Internally, France was dominated by the conflict with the House of Habsburg and the French Wars of Religion between Catholics and Huguenots. France was successful in the Thirty Years' War and further increased its influence during the reign of Louis XIV\"\n",
    "sentence = \"Come on John Doe what are you doing ?\"\n",
    "\n",
    "# Analyser la phrase avec spaCy\n",
    "doc = nlp(sentence)\n",
    "\n",
    "list_chunk_tag_index = []\n",
    "\n",
    "# Afficher les chunks taggés\n",
    "for chunk in doc:\n",
    "    chunk_tag_index = None\n",
    "    \n",
    "    # Identifier l'index de l'étiquette en fonction de la dépendance de la racine du chunk\n",
    "    if chunk.pos_ == \"LIST\":  # Liste\n",
    "        chunk_tag_index = 9 if chunk.dep_ == \"list\" else 10\n",
    "    elif chunk.pos_ == \"PROPN\" or chunk.pos_ == \"NOUN\":  # Nom propre\n",
    "        chunk_tag_index = 11 if chunk.i == 0 or (doc[chunk.i - 1].pos_ != \"NOUN\" and doc[chunk.i - 1].pos_ != \"PROPN\") else 12\n",
    "    elif chunk.pos_ == \"ADJ\":  # Adjectif\n",
    "        chunk_tag_index = 1 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"ADJ\" else 2\n",
    "    elif chunk.pos_ == \"ADP\":  # Préposition\n",
    "        chunk_tag_index = 13 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"ADP\" else 14\n",
    "    elif chunk.pos_ == \"VERB\" or chunk.pos_ == \"AUX\":  # Verbe\n",
    "        chunk_tag_index = 21 if chunk.i == 0 or (doc[chunk.i - 1].pos_ != \"VERB\" and doc[chunk.i - 1].pos_ != \"AUX\") else 22\n",
    "    elif chunk.pos_ == \"ADV\":  # Adverbe\n",
    "        chunk_tag_index = 3 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"ADV\" else 4\n",
    "    elif chunk.pos_ == \"CONJ\":  # Conjonction\n",
    "        chunk_tag_index = 5 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"CONJ\" else 6\n",
    "    elif chunk.pos_ == \"INTJ\":  # Interjection\n",
    "        chunk_tag_index = 7 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"INTJ\" else 8\n",
    "    elif chunk.pos_ == \"PART\":  # Particule\n",
    "        chunk_tag_index = 15 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"PART\" else 16\n",
    "    elif chunk.pos_ == \"SCONJ\":  # Subordinate Conjunction\n",
    "        chunk_tag_index = 17 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"SCONJ\" else 18\n",
    "    elif chunk.pos_ == \"X\":  # Autre\n",
    "        chunk_tag_index = 19 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"X\" else 20\n",
    "    else:\n",
    "        chunk_tag_index = 0\n",
    "\n",
    "    if chunk_tag_index is not None:\n",
    "        # chunk_tag = chunk_tags_mapping[chunk_tag_index]  # Obtenir l'étiquette de classification des chunks correspondante\n",
    "        print(chunk.text, \"-->\", chunk_tag_index)\n",
    "        list_chunk_tag_index.append(chunk_tag_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "835c3e2c-c2e3-4868-970a-0d187e2f65a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 13, 11, 12, 0, 21, 0, 21, 0]\n"
     ]
    }
   ],
   "source": [
    "print(list_chunk_tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "343d7784-f0a7-4183-b89a-0a5a5eff5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Classe\n",
    "@dataclass\n",
    "class Token:\n",
    "    id:int\n",
    "    forme:str\n",
    "    pos_tag:int\n",
    "    chunk_tag:int\n",
    "    ner_tag:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd7f63da-adb8-40f4-90b4-3a6a2ee32039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_tags(doc) -> list:\n",
    "\n",
    "    \"\"\"dict_chunk_tags = {\n",
    "        0: 'O', 1: 'B-ADJP', 2: 'I-ADJP', 3: 'B-ADVP', 4: 'I-ADVP',\n",
    "        5: 'B-CONJP', 6: 'I-CONJP', 7: 'B-INTJ', 8: 'I-INTJ',\n",
    "        9: 'B-LST', 10: 'I-LST', 11: 'B-NP', 12: 'I-NP',\n",
    "        13: 'B-PP', 14: 'I-PP', 15: 'B-PRT', 16: 'I-PRT',\n",
    "        17: 'B-SBAR', 18: 'I-SBAR', 19: 'B-UCP', 20: 'I-UCP',\n",
    "        21: 'B-VP', 22: 'I-VP'\n",
    "    }\"\"\"\n",
    "\n",
    "\n",
    "    list_chunk_tag_index = []\n",
    "\n",
    "    # Afficher les chunks taggés\n",
    "    for chunk in doc:\n",
    "\n",
    "        chunk_tag_index = None\n",
    "        \n",
    "        if chunk.pos_ == \"LIST\":  # Liste\n",
    "            chunk_tag_index = 9 if chunk.dep_ == \"list\" else 10\n",
    "        elif chunk.pos_ == \"PROPN\" or chunk.pos_ == \"NOUN\":  # Nom propre et nom\n",
    "            chunk_tag_index = 11 if chunk.i == 0 or (doc[chunk.i - 1].pos_ != \"NOUN\" and doc[chunk.i - 1].pos_ != \"PROPN\") else 12\n",
    "        elif chunk.pos_ == \"ADJ\":  # Adj\n",
    "            chunk_tag_index = 1 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"ADJ\" else 2\n",
    "        elif chunk.pos_ == \"ADP\":  # Préposition\n",
    "            chunk_tag_index = 13 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"ADP\" else 14\n",
    "        elif chunk.pos_ == \"VERB\" or chunk.pos_ == \"AUX\":  # Verbe et auxiliaire\n",
    "            chunk_tag_index = 21 if chunk.i == 0 or (doc[chunk.i - 1].pos_ != \"VERB\" and doc[chunk.i - 1].pos_ != \"AUX\") else 22\n",
    "        elif chunk.pos_ == \"ADV\":  # Adv\n",
    "            chunk_tag_index = 3 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"ADV\" else 4\n",
    "        elif chunk.pos_ == \"CONJ\":  # Conjonction\n",
    "            chunk_tag_index = 5 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"CONJ\" else 6\n",
    "        elif chunk.pos_ == \"INTJ\":  # Interjection\n",
    "            chunk_tag_index = 7 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"INTJ\" else 8\n",
    "        elif chunk.pos_ == \"PART\":  # Particule\n",
    "            chunk_tag_index = 15 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"PART\" else 16\n",
    "        elif chunk.pos_ == \"SCONJ\":  # Conjonction de subordination\n",
    "            chunk_tag_index = 17 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"SCONJ\" else 18\n",
    "        elif chunk.pos_ == \"X\":  # Les autres\n",
    "            chunk_tag_index = 19 if chunk.i == 0 or doc[chunk.i - 1].pos_ != \"X\" else 20\n",
    "        else:\n",
    "            chunk_tag_index = 0\n",
    "\n",
    "        if chunk_tag_index is not None:\n",
    "            list_chunk_tag_index.append(chunk_tag_index)\n",
    "\n",
    "    return list_chunk_tag_index\n",
    "\n",
    "def get_pos(doc) -> list:\n",
    "\n",
    "    dict_pos = {0 : \"ADJ\", 1 : \"ADP\", 2 : \"ADV\", \n",
    "                3 : \"AUX\", 4 : \"CCONJ\", 5 : \"DET\",\n",
    "                6 : \"INTJ\", 7 : \"NOUN\", 8 : \"NUM\",\n",
    "                9 : \"PART\", 10 : \"PRON\", 11 : \"PROPN\",\n",
    "                12 : \"PUNCT\", 13 : \"SCONJ\", 14 : \"SYM\",\n",
    "                15 : \"VERB\", 16 : \"X\", 17 : \"LIST\"}\n",
    "    \n",
    "\n",
    "    list_pos_index = []\n",
    "\n",
    "    for pos in doc:\n",
    "        pos_index = -1\n",
    "\n",
    "        for a, b in dict_pos.items():\n",
    "            if pos.pos_ == b:\n",
    "                pos_index = a\n",
    "                list_pos_index.append(pos_index)\n",
    "    return list_pos_index\n",
    "\n",
    "def get_ner_tags(doc) -> list:\n",
    "    \n",
    "    # dict_ner_tags = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "\n",
    "    list_tags = [\n",
    "    \"NORP\",\n",
    "    \"FAC\",\n",
    "    \"GPE\",\n",
    "    \"PRODUCT\",\n",
    "    \"EVENT\",\n",
    "    \"WORK_OF_ART\",\n",
    "    \"LAW\",\n",
    "    \"LANGUAGE\",\n",
    "    \"DATE\",\n",
    "    \"TIME\",\n",
    "    \"PERCENT\",\n",
    "    \"MONEY\",\n",
    "    \"QUANTITY\",\n",
    "    \"ORDINAL\",\n",
    "    \"CARDINAL\"]\n",
    "\n",
    "    list_ner_tags = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        ner_tag = \"\"\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            ner_tag = \"12\"\n",
    "        elif ent.label_ == \"ORG\":\n",
    "            ner_tag = \"34\"\n",
    "        elif ent.label_ == \"LOC\":\n",
    "            ner_tag = \"56\"\n",
    "        elif ent.label_ in list_tags:\n",
    "            ner_tag = \"78\"\n",
    "        list_ner_tags.append(ner_tag)\n",
    "\n",
    "    return list_ner_tags\n",
    "\n",
    "def get_tokens(corpus:str):\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    list_sents:list = sent_tokenize(corpus)\n",
    "    list_sents_nlp:list = []\n",
    "    list_tokens = []\n",
    "\n",
    "    for sent in list_sents:\n",
    "        sent_nlp = nlp(sent)\n",
    "        list_sents_nlp.append(sent_nlp)\n",
    "    \n",
    "    for i, sent in enumerate(list_sents_nlp):\n",
    "\n",
    "        list_tokens.append([])\n",
    "\n",
    "        for tok in sent:\n",
    "            token = Token(int(tok.i), str(tok.text), -1, -1, 0)\n",
    "            list_tokens[-1].append(token)\n",
    "        \n",
    "        for ii, chunk in enumerate(get_chunk_tags(sent)):\n",
    "            list_tokens[i][ii].chunk_tag = int(chunk)\n",
    "\n",
    "        for ii, pos in enumerate(get_pos(sent)):\n",
    "            list_tokens[i][ii].pos_tag = int(pos)\n",
    "\n",
    "        for ii, ner in enumerate(get_ner_tags(sent)):\n",
    "            if list_tokens[i][ii].chunk_tag % 2 != 0:\n",
    "                list_tokens[i][ii].ner_tag = int(ner[0])\n",
    "            else:\n",
    "                list_tokens[i][ii].ner_tag = int(ner[1])\n",
    "    \n",
    "    return list_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a650a0c4-66c2-4956-a612-9243aa7d6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "list_sents:list = sent_tokenize(sentence)\n",
    "list_sents_nlp:list = []\n",
    "list_tokens = []\n",
    "\n",
    "for sent in list_sents:\n",
    "    sent_nlp = nlp(sent)\n",
    "    list_sents_nlp.append(sent_nlp)\n",
    "\n",
    "for i, sent in enumerate(list_sents_nlp):\n",
    "\n",
    "    list_tokens.append([])\n",
    "\n",
    "    for tok in sent:\n",
    "        token = Token(int(tok.i), str(tok.text), -1, -1, 0)\n",
    "        list_tokens[-1].append(token)\n",
    "\n",
    "    for ii, chunk in enumerate(get_chunk_tags(sent)):\n",
    "        list_tokens[i][ii].chunk_tag = int(chunk)\n",
    "\n",
    "    for ii, pos in enumerate(get_pos(sent)):\n",
    "        list_tokens[i][ii].pos_tag = int(pos)\n",
    "    \n",
    "    list_ner = get_ner_tags(sent)\n",
    "    for ii, ner in enumerate(list_ner):\n",
    "        if list_tokens[i][ii].chunk_tag % 2 != 0:\n",
    "            list_tokens[i][ii].ner_tag = int(ner[0])\n",
    "        else:\n",
    "            list_tokens[i][ii].ner_tag = int(ner[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2352a9ee-f256-4cf0-8e74-b6110ea68d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tokens = get_tokens(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb0fb839-9be5-4355-9977-3007abecb0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Token(id=0, forme='Come', pos_tag=15, chunk_tag=21, ner_tag=0),\n",
       "  Token(id=1, forme='on', pos_tag=1, chunk_tag=13, ner_tag=0),\n",
       "  Token(id=2, forme='John', pos_tag=11, chunk_tag=11, ner_tag=0),\n",
       "  Token(id=3, forme='Doe', pos_tag=11, chunk_tag=12, ner_tag=0),\n",
       "  Token(id=4, forme='what', pos_tag=10, chunk_tag=0, ner_tag=0),\n",
       "  Token(id=5, forme='are', pos_tag=3, chunk_tag=21, ner_tag=0),\n",
       "  Token(id=6, forme='you', pos_tag=10, chunk_tag=0, ner_tag=0),\n",
       "  Token(id=7, forme='doing', pos_tag=15, chunk_tag=21, ner_tag=0),\n",
       "  Token(id=8, forme='?', pos_tag=12, chunk_tag=0, ner_tag=0)]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(list_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "519e0d90-50b9-4889-b433-892d82db3c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Come', 'on', 'John', 'Doe', 'what', 'are', 'you', 'doing', '?']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sent in list_tokens:\n",
    "    list_formes = [tok.forme for tok in sent]\n",
    "    list_pos = [tok.pos_tag for tok in sent]\n",
    "    list_chunk = [tok.chunk_tag for tok in sent]\n",
    "    list_ners = [tok.ner_tag for tok in sent]\n",
    "display(list_formes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26896e3e-8300-4127-9b24-965ac15e8467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 1, 11, 11, 10, 3, 10, 15, 12]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(list_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd729fd2-5625-4976-8cb6-f825cbcec774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 13, 11, 12, 0, 21, 0, 21, 0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(list_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab43bc3b-89db-4348-97d9-a5139b1fe114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(list_ners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6174c4-a4d8-46fb-84c7-1dc886f0fb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
